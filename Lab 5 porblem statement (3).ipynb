{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ce141c",
   "metadata": {
    "id": "57ce141c"
   },
   "source": [
    "# <font color=darkblue> Machine Learning model deployment with Flask framework on Heroku</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1bdb38",
   "metadata": {
    "id": "ba1bdb38"
   },
   "source": [
    "## <font color=Blue>Used Cars Price Prediction Application</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6492286d",
   "metadata": {
    "id": "6492286d"
   },
   "source": [
    "### Objective:\n",
    "1. To build a Machine learning regression model to predict the selling price of the used cars based on the different input features like fuel_type, kms_driven, type of transmission etc.\n",
    "2. Deploy the machine learning model with flask framework on heroku."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa174ee",
   "metadata": {
    "id": "6fa174ee"
   },
   "source": [
    "### Dataset Information:\n",
    "#### Dataset Source: https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho?select=CAR+DETAILS+FROM+CAR+DEKHO.csv\n",
    "This dataset contains information about used cars listed on www.cardekho.com\n",
    "- **Car_Name**: Name of the car\n",
    "- **Year**: Year of Purchase\n",
    "- **Selling Price (target)**: Selling price of the car in lakhs\n",
    "- **Present Price**: Present price of the car in lakhs\n",
    "- **Kms_Driven**: kilometers driven\n",
    "- **Fuel_Type**: Petrol/diesel/CNG\n",
    "- **Seller_Type**: Dealer or Indiviual\n",
    "- **Transmission**: Manual or Automatic\n",
    "- **Owner**: first, second or third owner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4059ba6",
   "metadata": {
    "id": "e4059ba6"
   },
   "source": [
    "### 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ee2764",
   "metadata": {
    "id": "f6ee2764"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189ac5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567dc2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c79a95e",
   "metadata": {
    "id": "8c79a95e"
   },
   "source": [
    "### 2. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1a9544",
   "metadata": {
    "id": "9a1a9544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Car_Name  Year  Selling_Price  Present_Price  Kms_Driven  \\\n",
      "278             jazz  2016           6.00           8.40        4000   \n",
      "257             city  2015           8.50          13.60       40324   \n",
      "87     corolla altis  2012           5.90          13.74       56000   \n",
      "155  Honda Activa 4G  2017           0.48           0.51        4300   \n",
      "156       TVS Sport   2017           0.48           0.52       15000   \n",
      "\n",
      "    Fuel_Type Seller_Type Transmission  Owner  \n",
      "278    Petrol      Dealer       Manual      0  \n",
      "257    Petrol      Dealer       Manual      0  \n",
      "87     Petrol      Dealer       Manual      0  \n",
      "155    Petrol  Individual    Automatic      0  \n",
      "156    Petrol  Individual       Manual      0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('car+data.csv')\n",
    "# Display a sample of five rows\n",
    "sample = df.sample(n=5)  \n",
    "# randomly select 5 rows from the DataFrame\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13204bc7",
   "metadata": {
    "id": "13204bc7"
   },
   "source": [
    "### 3. Check the shape and basic information of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd100657",
   "metadata": {
    "id": "dd100657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame:\n",
      "(301, 9)\n",
      "\n",
      "General information about the DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 301 entries, 0 to 300\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Car_Name       301 non-null    object \n",
      " 1   Year           301 non-null    int64  \n",
      " 2   Selling_Price  301 non-null    float64\n",
      " 3   Present_Price  301 non-null    float64\n",
      " 4   Kms_Driven     301 non-null    int64  \n",
      " 5   Fuel_Type      301 non-null    object \n",
      " 6   Seller_Type    301 non-null    object \n",
      " 7   Transmission   301 non-null    object \n",
      " 8   Owner          301 non-null    int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 21.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the data (number of rows and columns)\n",
    "print(\"Shape of the DataFrame:\")\n",
    "print(df.shape)\n",
    "\n",
    "# Check general information about the DataFrame\n",
    "print(\"\\nGeneral information about the DataFrame:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69c8bc1",
   "metadata": {
    "id": "e69c8bc1"
   },
   "source": [
    "### 4. Check for the presence of the duplicate records in the dataset? If present drop them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0456bdd",
   "metadata": {
    "id": "d0456bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate records: 2\n",
      "Dropping duplicate records...\n",
      "Duplicate records dropped.\n",
      "\n",
      "First 5 rows of the dataframe after dropping duplicates:\n",
      "  Car_Name  Year  Selling_Price  Present_Price  Kms_Driven Fuel_Type  \\\n",
      "0     ritz  2014           3.35           5.59       27000    Petrol   \n",
      "1      sx4  2013           4.75           9.54       43000    Diesel   \n",
      "2     ciaz  2017           7.25           9.85        6900    Petrol   \n",
      "3  wagon r  2011           2.85           4.15        5200    Petrol   \n",
      "4    swift  2014           4.60           6.87       42450    Diesel   \n",
      "\n",
      "  Seller_Type Transmission  Owner  \n",
      "0      Dealer       Manual      0  \n",
      "1      Dealer       Manual      0  \n",
      "2      Dealer       Manual      0  \n",
      "3      Dealer       Manual      0  \n",
      "4      Dealer       Manual      0  \n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate records\n",
    "is_duplicate = df.duplicated()\n",
    "duplicate_count = is_duplicate.sum()\n",
    "\n",
    "if duplicate_count > 0:\n",
    "    print(\"Number of duplicate records:\", duplicate_count)\n",
    "    print(\"Dropping duplicate records...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(\"Duplicate records dropped.\")\n",
    "else:\n",
    "    print(\"No duplicate records found.\")\n",
    "\n",
    "# Print the first 5 rows of the dataframe after dropping duplicates\n",
    "print(\"\\nFirst 5 rows of the dataframe after dropping duplicates:\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef965d82",
   "metadata": {
    "id": "ef965d82"
   },
   "source": [
    "### 5. Drop the columns which you think redundant for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48e26af1",
   "metadata": {
    "id": "48e26af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redundant columns dropped and new CSV file saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = 'car+data.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# List of columns you consider redundant\n",
    "redundant_columns = [\"Owner\"]\n",
    "\n",
    "# Drop the redundant columns\n",
    "df.drop(columns=redundant_columns, inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "new_csv_file_path = \"car+data_modified.csv\"\n",
    "df.to_csv(new_csv_file_path, index=False)\n",
    "\n",
    "print(\"Redundant columns dropped and new CSV file saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4a84d",
   "metadata": {
    "id": "38e4a84d"
   },
   "source": [
    "### 6. Extract a new feature called 'age_of_the_car' from the feature 'year' and drop the feature year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eff4fb15",
   "metadata": {
    "id": "eff4fb15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'age_of_the_car' feature extracted and 'Year' column dropped.\n",
      "0       9\n",
      "1      10\n",
      "2       6\n",
      "3      12\n",
      "4       9\n",
      "       ..\n",
      "296     7\n",
      "297     8\n",
      "298    14\n",
      "299     6\n",
      "300     7\n",
      "Name: age_of_the_car, Length: 301, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = \"car+data.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Calculate the current year\n",
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "# Create the new 'age_of_the_car' feature\n",
    "df['age_of_the_car'] = current_year - df['Year']\n",
    "\n",
    "# Drop the 'year' column\n",
    "df.drop(columns=['Year'], inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "new_csv_file_path = \"car+data_modified.csv\"\n",
    "df.to_csv(new_csv_file_path, index=False)\n",
    "\n",
    "print(\"'age_of_the_car' feature extracted and 'Year' column dropped.\")\n",
    "print(df['age_of_the_car'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14100a4",
   "metadata": {
    "id": "b14100a4"
   },
   "source": [
    "### 7. Encode the categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f8a038",
   "metadata": {
    "id": "14f8a038"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = \"car+data.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# List of categorical columns to one-hot encode\n",
    "categorical_columns = ['Car_Name','Fuel_Type', 'Seller_Type', 'Transmission']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Save the encoded DataFrame to a new CSV file\n",
    "encoded_csv_file_path = \"car+data_modified.csv\"\n",
    "df_encoded.to_csv(encoded_csv_file_path, index=False)\n",
    "\n",
    "print(\"Categorical columns one-hot encoded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5666bce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features normalized.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = \"car+data.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Specify the column names for the numerical features\n",
    "numerical_features = [\"Selling_Price\",\"Present_Price\",\"Kms_Driven\"]\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply normalization to the numerical features\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "normalized_csv_file_path = \"car+data_modified.csv\"\n",
    "df.to_csv(normalized_csv_file_path, index=False)\n",
    "\n",
    "print(\"Numerical features normalized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf17c9e",
   "metadata": {
    "id": "0cf17c9e"
   },
   "source": [
    "### 8. Separate the target and independent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37931ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (301, 3)\n",
      "Shape of y: (301,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "csv_file_path = \"car+data_modified.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Specify the index/column positions for the target and independent features\n",
    "target_column_index = 0  # Replace with the actual index of the target column\n",
    "independent_feature_indices = [3, 4, 5]  # Replace with the actual indices of the feature columns\n",
    "\n",
    "# Separate the target variable and independent features using .iloc\n",
    "X = df.iloc[:, independent_feature_indices]\n",
    "y = df.iloc[:, target_column_index]\n",
    "\n",
    "# Display shapes of X and y (optional)\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7962944",
   "metadata": {
    "id": "a7962944"
   },
   "source": [
    "### 9. Split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8ee4942",
   "metadata": {
    "id": "b8ee4942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (240, 8) (240,)\n",
      "Test set shape: (61, 8) (61,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Load the .csv file into a pandas DataFrame if not done already\n",
    "df = pd.read_csv('car+data_modified.csv')\n",
    "\n",
    "# Step 2: Separate the target variable and independent features\n",
    "target = df['Car_Name']\n",
    "independent_features = df.drop('Kms_Driven', axis=1)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "# The test_size parameter specifies the proportion of the data to be used for testing (e.g., 0.2 means 20% for testing)\n",
    "# The random_state parameter is used to ensure reproducibility of the split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optionally, you can print the shape of the train and test sets to see the sizes.\n",
    "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bebd320",
   "metadata": {
    "id": "0bebd320"
   },
   "source": [
    "### 10. Build a Random forest Regressor model and check the r2-score for train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "150c01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4426229508196721\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Load the .csv file into a pandas DataFrame if not done already\n",
    "df = pd.read_csv('car+data_modified.csv')\n",
    "\n",
    "# Step 2: Separate the target variable and independent features\n",
    "target = df['Car_Name']\n",
    "independent_features = df.drop('Car_Name', axis=1)  # Drop the target column\n",
    "\n",
    "# Perform one-hot encoding on the categorical features\n",
    "independent_features_encoded = pd.get_dummies(independent_features)\n",
    "\n",
    "# Step 3: Split the data into training and testing sets\n",
    "# The test_size parameter specifies the proportion of the data to be used for testing (e.g., 0.2 means 20% for testing)\n",
    "# The random_state parameter is used to ensure reproducibility of the split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_features_encoded, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Initialize the Random Forest Classifier model\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Step 5: Train the model on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Predict on the test data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Step 7: Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e089c8",
   "metadata": {
    "id": "26e089c8"
   },
   "source": [
    "### 11. Create a pickle file with an extension as .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41d6bb75",
   "metadata": {
    "id": "41d6bb75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame pickled and saved to model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "csv_file_path = 'car+data_modified.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Specify the file path for the pickle file\n",
    "pickle_file_path = 'model.pkl'\n",
    "\n",
    "# Save the DataFrame as a pickle file\n",
    "with open(pickle_file_path, 'wb') as file:\n",
    "    pickle.dump(df, file)\n",
    "\n",
    "print(f\"DataFrame pickled and saved to {pickle_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5bb0c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded DataFrame:     Car_Name  Year  Selling_Price  Present_Price  Kms_Driven Fuel_Type  \\\n",
      "0       ritz  2014       0.093123       0.057109    0.053053    Petrol   \n",
      "1        sx4  2013       0.133238       0.099913    0.085085    Diesel   \n",
      "2       ciaz  2017       0.204871       0.103273    0.012813    Petrol   \n",
      "3    wagon r  2011       0.078797       0.041504    0.009409    Petrol   \n",
      "4      swift  2014       0.128940       0.070980    0.083984    Diesel   \n",
      "..       ...   ...            ...            ...         ...       ...   \n",
      "296     city  2016       0.269341       0.122237    0.067043    Diesel   \n",
      "297     brio  2015       0.111748       0.060468    0.119119    Petrol   \n",
      "298     city  2009       0.093123       0.115735    0.175043    Petrol   \n",
      "299     city  2017       0.326648       0.131990    0.017017    Diesel   \n",
      "300     brio  2016       0.148997       0.060468    0.009938    Petrol   \n",
      "\n",
      "    Seller_Type Transmission  Owner  \n",
      "0        Dealer       Manual      0  \n",
      "1        Dealer       Manual      0  \n",
      "2        Dealer       Manual      0  \n",
      "3        Dealer       Manual      0  \n",
      "4        Dealer       Manual      0  \n",
      "..          ...          ...    ...  \n",
      "296      Dealer       Manual      0  \n",
      "297      Dealer       Manual      0  \n",
      "298      Dealer       Manual      0  \n",
      "299      Dealer       Manual      0  \n",
      "300      Dealer       Manual      0  \n",
      "\n",
      "[301 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Specify the file path of the pickle file\n",
    "pickle_file_path = 'model.pkl'\n",
    "\n",
    "# Load the pickled DataFrame\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    loaded_df = pickle.load(file)\n",
    "\n",
    "print(\"Loaded DataFrame:\", loaded_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af654594",
   "metadata": {
    "id": "af654594"
   },
   "source": [
    "### 12. Create new folder/new project in visual studio/pycharm that should contain the \"model.pkl\" file *make sure you are using a virutal environment and install required packages.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57524891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from Flask) (2.0.3)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from Flask) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from Flask) (2.0.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from Flask) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from click>=5.1->Flask) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from Jinja2>=2.10.1->Flask) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498fd939",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (645207457.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\hpg13\\AppData\\Local\\Temp\\ipykernel_13844\\645207457.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    flask run\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "flask run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7bd95",
   "metadata": {
    "id": "c0b7bd95"
   },
   "source": [
    "### a) Create a basic HTML form for the frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae9c89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load your data and perform feature engineering\n",
    "# X_train, y_train = ...\n",
    "\n",
    "# Create and train the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model as a pickled file\n",
    "with open('model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "daa45a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hpg13\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7a95db",
   "metadata": {
    "id": "5a7a95db"
   },
   "source": [
    "a)Create a file **index.html** in the templates folder and copy the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d254f30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Car Price Prediction</title>\n",
    "    <link rel=\"stylesheet\" href=\"index.css\">\n",
    "    <header>\n",
    "        <h1>Car Price Prediction</h1>\n",
    "    </header>\n",
    "</head>\n",
    "\n",
    "<body>\n",
    "\n",
    "    <form action=\"/predict\" method=\"post\">\n",
    "        <br>\n",
    "        <label for=\"year\">Year:</label>\n",
    "        <input type=\"text\" id=\"year\" name=\"year\" required><br><br>\n",
    "        <label for=\"present_price\">Present Price:</label>\n",
    "        <input type=\"text\" id=\"present_price\" name=\"present_price\" required><br><br>\n",
    "        <br>\n",
    "        <link rel=\"stylesheet\" href=\"app.py\">\n",
    "                    <button onclick=\"window.open('app.py','_blank');\"><a href=\"#\">Predict</a></button>\n",
    "        <br>\n",
    "        <br>\n",
    "        <div class=\"images\">\n",
    "            <div class=\"photo\">\n",
    "                <img src=\"C:\\Users\\hpg13\\OneDrive\\Desktop\\LAB_5\\templates\\car1.jpg\"alt=\"photo\" />\n",
    "                <img src= \"C:\\Users\\hpg13\\OneDrive\\Desktop\\LAB_5\\templates\\Car2.jpg\"alt=\"photo\" />\n",
    "            </div>\n",
    "    </form>\n",
    "</body>\n",
    "\n",
    "<footer>\n",
    "    <br>\n",
    "\n",
    "\n",
    "    <br>\n",
    "    <nav id=\"naviagte\">\n",
    "        <ul class=\"footer\">\n",
    "            <li>\n",
    "                <a href=\"#\">@Copyright. This page is to be used only for demonstration purposes.</a>\n",
    "            </li>\n",
    "        </ul>\n",
    "    </nav>\n",
    "</footer>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ecf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.css\n",
    "\n",
    "header h1 {\n",
    "    background-color: darkgrey;\n",
    "    margin: 0%;\n",
    "    padding: 30px;\n",
    "    text-align: center;\n",
    "    font-size: 40px;\n",
    "}\n",
    "body {\n",
    "    height: auto;\n",
    "    margin: 0%;\n",
    "    background-color:lightgray;\n",
    "    text-align: center;\n",
    "    font-family:'calibri', Times, serif;\n",
    "    \n",
    "}\n",
    ".photo {\n",
    "    position: relative;\n",
    "    overflow: hidden;\n",
    "    width: 700px; /* Adjust the width as needed */\n",
    "    height: 500px; /* Adjust the height as needed */\n",
    "    display: block;\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "  }\n",
    "\n",
    "  .photo img {\n",
    "    position: relative;\n",
    "    padding: 10px;\n",
    "    max-width: 100%;\n",
    "    max-height: 100%;\n",
    "    object-fit: cover;\n",
    "}\n",
    " button{\n",
    "    width: 80px;\n",
    "    height: 20px;\n",
    "    padding: 5px;\n",
    "\n",
    "    background-color:gray;\n",
    "    box-sizing: content-box;\n",
    "    color: whitesmoke;\n",
    "    font-family:'calibri', Times, serif;\n",
    "\n",
    "}\n",
    "\n",
    ".footer {\n",
    "    margin: 0%;\n",
    "    padding: 10px;\n",
    "    background-color: black;\n",
    "    text-align: right;\n",
    "}\n",
    "\n",
    ".footer li a {\n",
    "    color: white;\n",
    "    font-size: 15px;\n",
    "    text-decoration: none;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2844d781",
   "metadata": {
    "id": "2844d781"
   },
   "source": [
    "### b) Create app.py file and write the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c40bdac",
   "metadata": {
    "id": "7c40bdac"
   },
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Load the pickled model\n",
    "    with open('model.pkl', 'rb') as file:\n",
    "        loaded_model = pickle.load(file)\n",
    "\n",
    "    # Get input from the form\n",
    "    feature_1 = float(request.form['feature_1'])\n",
    "    # Add more lines to get other feature values\n",
    "\n",
    "    # Perform prediction using the loaded model\n",
    "    prediction = loaded_model.predict([[feature_1]])  # Adjust input format as needed\n",
    "\n",
    "    return f\"Predicted Car Price: {prediction[0]}\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ed8de",
   "metadata": {
    "id": "028ed8de"
   },
   "source": [
    "### 13. Deploy your app on Heroku. (write commands for deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997b74d",
   "metadata": {
    "id": "8997b74d"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80008b60",
   "metadata": {
    "id": "80008b60"
   },
   "source": [
    "### 14. Paste the URL of the heroku application below, and while submitting the solution submit this notebook along with the source code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ccccf",
   "metadata": {
    "id": "dc9ccccf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5a533a5",
   "metadata": {
    "id": "c5a533a5"
   },
   "source": [
    "### Happy Learning :)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab Session.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
